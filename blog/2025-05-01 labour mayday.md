# notes form today
- ollama; tool to run locally AI on your computer! https://github.com/ollama/ollama Installing on macos is simple as opening terminal and typing `brew install ollama`
-  page to look up AI models: https://huggingface.co
- use local models with vscode instead of cloud AI like Copilot: https://www.continue.dev
- there is open source vscode called `vscodium` https://vscodium.com
- macos and macbooks Air and Pro have a better price to funcions ratio for using LLMs locally
- still windows WSL and linux are better in some DevOps stuff like building locally docker image (who doeas that in cloud era?!)
- so i think unless i really want to play and buy myself gpd laptop with rtx for coding, devops expedriments and local llm experiments macs are good engough 